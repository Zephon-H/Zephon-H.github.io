<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.zephon.ml","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="卷积神经网络-实例探究 为什么要进行实例分析？  之前已经了解过了卷积神经网络的一些基本知识-卷积层、池化层、全连接层等，人们花费许多时间在探究如何将这些不同的层进行连接形成有更有效的神经网络，而找到这种方法(或感觉)的最好方法之一就是看一些实例。">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络-实例探究">
<meta property="og:url" content="http://www.zephon.ml/2020/12/26/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/index.html">
<meta property="og:site_name" content="Zephon Blog">
<meta property="og:description" content="卷积神经网络-实例探究 为什么要进行实例分析？  之前已经了解过了卷积神经网络的一些基本知识-卷积层、池化层、全连接层等，人们花费许多时间在探究如何将这些不同的层进行连接形成有更有效的神经网络，而找到这种方法(或感觉)的最好方法之一就是看一些实例。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226211935913.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226212903842.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226214414518.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226221805757.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226222440538.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226224134777.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226224639302.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226230148608.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226232038321.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227112249498.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227113212477.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227113723554.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227172240582.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227173532543.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227175302682.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227180138230.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227180944240.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227181212935.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227181730903.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227182327667.png">
<meta property="og:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227215302872.png">
<meta property="article:published_time" content="2020-12-26T04:18:32.000Z">
<meta property="article:modified_time" content="2021-12-31T17:09:29.007Z">
<meta property="article:author" content="Zephon">
<meta property="article:tag" content="计算机视觉">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226211935913.png">

<link rel="canonical" href="http://www.zephon.ml/2020/12/26/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>卷积神经网络-实例探究 | Zephon Blog</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?697784f78fd83128cc519aedf69e3017";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband">
	<a target="_blank" rel="noopener" href="https://github.com/Zephon-H" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
	</div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zephon Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-download">

    <a href="/download/" rel="section"><i class="fa fa-download fa-fw"></i>下载</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.zephon.ml/2020/12/26/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.gif">
      <meta itemprop="name" content="Zephon">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zephon Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          卷积神经网络-实例探究
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-26 12:18:32" itemprop="dateCreated datePublished" datetime="2020-12-26T12:18:32+08:00">2020-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-01-01 01:09:29" itemprop="dateModified" datetime="2022-01-01T01:09:29+08:00">2022-01-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="卷积神经网络-实例探究">卷积神经网络-实例探究</h1>
<h2 id="为什么要进行实例分析">为什么要进行实例分析？</h2>
<blockquote>
<p>之前已经了解过了卷积神经网络的一些基本知识-卷积层、池化层、全连接层等，人们花费许多时间在探究如何将这些不同的层进行连接形成有更有效的神经网络，而找到这种方法(或感觉)的最好方法之一就是看一些实例。</p>
</blockquote>
<h2 id="经典网络">经典网络</h2>
<h3 id="lenet-5">LeNet-5</h3>
<p>LeNet-5是针对灰度图像训练的，所以输入通道只有1，结构如图</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226211935913.png" alt="image-20201226211935913" /><figcaption>image-20201226211935913</figcaption>
</figure>
<blockquote>
<p>包含约6万个参数</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition">参考文献:Gradient-Based Learning Applied to Document Recognition</a></p>
<h3 id="alexnet">AlexNet</h3>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226212903842.png" alt="image-20201226212903842" /><figcaption>image-20201226212903842</figcaption>
</figure>
<blockquote>
<p>AlexNet和LeNet类似，但更大，包含约6000万个参数</p>
<p>使用了ReLU激活函数</p>
<p>多GPU</p>
<p><del>LRN层：局部响应归一化层(Local Response Normalization)</del></p>
</blockquote>
<p><a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf">参考文献:ImageNet Classification with Deep Convolutional Neural Networks</a></p>
<h3 id="vggnetvgg-16">VGGNet(VGG-16)</h3>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226214414518.png" alt="image-20201226214414518" /><figcaption>image-20201226214414518</figcaption>
</figure>
<blockquote>
<p>VGG-16中的16指在网络中包含16个卷积层和全连接层</p>
<p>总共包含约1.38亿个参数</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.1556">参考文献:Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p>
<h2 id="残差网络residual-networksresnets">残差网络(Residual Networks(ResNets))</h2>
<h3 id="残差块residual-block">残差块(Residual block)</h3>
<p>ResNets是由残差块构建的</p>
<p>如图是一个两层神经网络，在L层进行激活，得到<span class="math inline">\(a^{[l+1]}\)</span>再次进行激活，两层之后，得到<span class="math inline">\(a^{[l+2]}\)</span> <span class="math display">\[
a^{[l]} \xrightarrow[z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]}]{} Linear \rightarrow ReLU \xrightarrow[a^{[l+1]}=g(z^{[l+1]})]{a^{[l+1]}}Linear \xrightarrow[z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}]{} \\ ReLU \xrightarrow[a^{[l+2]}=g(z^{[l+2]})]{} a^{[l+2]}
\]</span> 换句话说，从<span class="math inline">\(a^{[l]}\)</span>到<span class="math inline">\(a^{[l+2]}\)</span>，需要经过以上所有步骤，即这些网络的主路径</p>
<p>在残差网络中有一点变化，将<span class="math inline">\(a^{[l]}\)</span>直接迅速向后拷贝到神经网络的深层，在ReLU非线性激活前加上<span class="math inline">\(a^{[l]}\)</span>，构成一条捷径"short cut"(远跳连接"skip connection")，意味着最后的<span class="math inline">\(a^{[l+2]}=g(z^{[l+2]})\)</span>去掉了，取而代之的是<span class="math inline">\(a^{[l+2]}=g(z^{[l+2]}+a^{[l]})\)</span></p>
<p>通过这种残差块的方式，能够训练更深的神经网络，所以构建一个ResNet网络，就是通过将很多这样的残差块堆积在一起，形成一个深度神经网络</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226221805757.png" alt="image-20201226221805757" /><figcaption>image-20201226221805757</figcaption>
</figure>
<h3 id="残差网络residual-network">残差网络(Residual Network)</h3>
<p>如图是一个"Plain Network"，将它变成"ResNet"的方法是，加上所有的"skip connections"/"shortcut connections"，和前面一样，第两层增加一个捷径，构成一个残差块，5个残差块连接在一起，构成一个残差网络</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226222440538.png" alt="image-20201226222440538" /><figcaption>image-20201226222440538</figcaption>
</figure>
<p>如图下面部分，在"Plain Network"中，虽然理论上应该神经网络层数越深，错误率越低，但实际上却往往会先下降再上升，而ResNet中则几乎会一起下降</p>
<p><a href="">参考文献</a></p>
<h2 id="残差网络会什么有用">残差网络会什么有用？</h2>
<p>如图，假设有一个大型神经网络，输入为X，输出激活值<span class="math inline">\(a^{[l]}\)</span>,如果想增加这个神经网络的深度，方便起见，假设使用的激活函数都是ReLU，且激活值a大于等于0，</p>
<p>如果增加两层，将这两层看作一个残差块，则<span class="math inline">\(a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})\)</span>，</p>
<p>如果<span class="math inline">\(W^{[l+2]}=0,b^{[l+1]}=0\)</span>，则<span class="math inline">\(a^{[l+2]}=g(a^{[l]})\)</span>，则<span class="math inline">\(a^{[l+2]}=a^{[l]}\)</span></p>
<p><img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226224134777.png" /></p>
<blockquote>
<p>结果表明，残差块学习这个恒等函数并不难，"skip connection"帮助我们很容易得到<span class="math inline">\(a^{[l+2]}=a^{[l]}\)</span>，这也就意味着，即使给这个网络增加了这两层，它的效率也并不逊色于更简单的神经网络</p>
<p>当然，如果这些新增的隐藏层单元可以学到一些有用的信息，那么它可能会比恒等函数表现的更好</p>
</blockquote>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226224639302.png" alt="image-20201226224639302" /><figcaption>image-20201226224639302</figcaption>
</figure>
<h2 id="网络中的网络network-in-network和11卷积">网络中的网络(Network in Network)和1×1卷积</h2>
<h3 id="为什么11卷积">为什么1×1卷积？</h3>
<p>如图，将一个6×6×1的图片，与一个1×1×1的过滤器作卷积，相当于把这个图片中每个数字乘以2，这对单通道图片而言，看上去并没有什么效果；</p>
<p>但如果是一张6×6×32的图片，与一个1×1×32的过滤器作卷积，</p>
<p>具体来说，1×1卷积所实现的功能是：遍历这36个单元格，计算左图中32个数字和过滤器中32个数字的元素智能乘积(Element wise product)，然后应用ReLU非线性函数，得到一个实数，作为输出中的一个元素</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226230148608.png" alt="image-20201226230148608" /><figcaption>image-20201226230148608</figcaption>
</figure>
<blockquote>
<p>1×1卷积可以从根本上理解为：这32个单元都应用了一个全连接神经网络，全连接层的作用是输入32个数字，和过滤器数量，在6×6=36个单元上重复进行，输出结果是6×6×过滤器数量，以便在输入层上实施一个"pretty non-trivial computation"，这种方法通常被称为1×1卷积，有时也称为Network in Network</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/pdf/1312.4400">参考文献:Network In Network</a>)</p>
<h3 id="卷积的一个应用">1×1卷积的一个应用</h3>
<p>如图，有一个28×28×129的输入层，可以使用池化层压缩它的高度和宽度，但是，如果通道数量很大，该如何压缩呢？</p>
<p>可以使用32个大小为1×1的过滤器，严格地说是1×1×192，输出层为28×28×32，这就是压缩<span class="math inline">\(n_c\)</span>的方法，然而池化层，则只是压缩了这些层的高度和宽度</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201226232038321.png" alt="image-20201226232038321" /><figcaption>image-20201226232038321</figcaption>
</figure>
<h2 id="inception-network">Inception Network</h2>
<h3 id="motivation-for-inception-network">Motivation for Inception Network</h3>
<blockquote>
<p>Inception Network的作用就是你替你决定过滤器的大小究竟是多少或要不要添加池化层等，但它会让网络架构变得更加复杂，但网络表现却很好</p>
</blockquote>
<p>如图，是一个28×28×192的输入层，Inception Network或Inception Layer的作用是代替人工决定卷积层中的过滤器类型或确定是否需要创建卷积层或池化层</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227112249498.png" alt="image-20201227112249498" /><figcaption>image-20201227112249498</figcaption>
</figure>
<blockquote>
<p>基本思想是Inception Network不需要选择使用哪个过滤器或是池化，而是由网络自行确定这些参数，然后将这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些过滤器组合</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://www.researchgate.net/publication/305196650_Going_deeper_with_convolutions">参考文献:Going deeper with convolutions</a></p>
<h3 id="计算成本的问题">计算成本的问题</h3>
<p>将重点放在上述图中的5×5过滤器，则如下图</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227113212477.png" alt="image-20201227113212477" /><figcaption>image-20201227113212477</figcaption>
</figure>
<p>计算这个28×28×32输出的计算成本：</p>
<p>它有32个过滤器，因为输出有32个通道，每个过滤器大小为5×5×192，输出大小是20×20×32，所以要计算(28×28×32)个数字， 对于输出中的每个数字而言，都要执行(5×5×192)次乘法运算，所以乘法运算的总次数为每个输出值所需的乘法运算次数乘以输出值的个数((28×28×32)×(5×5×192))=1.2亿</p>
<h3 id="使用11卷积">使用1×1卷积</h3>
<p>如图，和上述计算有相同的输入和输出</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227113723554.png" alt="image-20201227113723554" /><figcaption>image-20201227113723554</figcaption>
</figure>
<blockquote>
<p>事实证明，只要合理构建瓶颈层，既可以显著缩小表示层规模，又不会降低网络性能，从而大量节省了计算。</p>
</blockquote>
<h3 id="inception-模块">Inception 模块</h3>
<p>Inception模块会将之前层的激活或输出作为它的输入</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227172240582.png" alt="image-20201227172240582" /><figcaption>image-20201227172240582</figcaption>
</figure>
<h3 id="inception-network-1">Inception Network</h3>
<p>如图，可以发现图中有许多重复的模块，如果只取其中一部分，会发现它就是之前的Inception模块，有的还会有一些额外的最大池化层，Inception Network其实只是许多之前据说的Inception Module在不同位置重复组成的网络。</p>
<p>此外，网络中其实还有一些分支，在网络的最后几层，通常称为全连接层，之后是一个Softmax层来做预测，而这些分支所做的就是通过隐藏层来做出预测，所以其实是一个softmax输出，它确保了即便是隐藏单元和中间层也参与了特征计算，也能预测图片的分类，在Inception Network中直到一种调整的效果，并能防止过拟合</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227173532543.png" alt="image-20201227173532543" /><figcaption>image-20201227173532543</figcaption>
</figure>
<h2 id="迁移学习">迁移学习</h2>
<blockquote>
<p>Eg：假设需要建立一个猫的检测器，需要检测图片中的是A类猫还是B类猫还是都不是，忽略两种猫同时出现在一张图片里的情况</p>
</blockquote>
<p>现在，对于这个任务，可能没有大量的相关图片，所以训练集会很小，可以从网上下载一些神经网络开源的实现，除了代码外，权重也需要下载，如ImageNet数据集对应的，它有1000个不同的类别，因此有一个Softmax单元，可以去掉这个softmax单元，然后创建用于这个任务的softmax单元来输出A、B、N三个类别，就网络而言，可以将前面所有层都看作是冻结的，网络中所有层的参数都是被冻结的，只需要训练和softmax有关的参数，通过使用其它人预训练的权重，可能可以得到很好的性能，即使只有一个小的数据集。</p>
<p>并且，对于大多数神经网络，都支持这种迁移操作，事实上，取决于使用的框架，也许有trainableParameter=0这样的参数，对于冻结的层，可以设置这个参数来让网络不训练这些权重，有时也是freeze=1等</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227175302682.png" alt="image-20201227175302682" /><figcaption>image-20201227175302682</figcaption>
</figure>
<blockquote>
<p>加速训练的一个技巧：</p>
<p>将冻结部分最后层的计算的特征或激活值，然后存到硬盘中，进而对于每个输入x，可以直接映射到冻结部分的最后输出，相当于在训练时缩短了神经网络的层数。</p>
</blockquote>
<p>而如果训练集的大小更大一些，则可以冻结更少的层</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227180138230.png" alt="image-20201227180138230" /><figcaption>image-20201227180138230</figcaption>
</figure>
<p>而如果训练集足够大，则应该将下载的权重当做初始化，然后训练网络</p>
<h2 id="数据增强data-augmentation">数据增强(Data Augmentation)</h2>
<blockquote>
<p>大部分的计算机视觉任务使用很多的数据，数据增强是一种经常用来提高计算机视觉系统表现的技巧</p>
</blockquote>
<h3 id="普通增强方法">普通增强方法</h3>
<p>垂直镜像对称方法(Mirroring)：</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227180944240.png" alt="image-20201227180944240" /><figcaption>image-20201227180944240</figcaption>
</figure>
<p>随机裁剪(Random Cropping)：</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227181212935.png" alt="image-20201227181212935" /><figcaption>image-20201227181212935</figcaption>
</figure>
<p>以上两种是经常被使用的，但理论上，也可以使用旋转(rotation)、剪切(shearing)、局部弯曲(local warping)等</p>
<h3 id="颜色转换">颜色转换</h3>
<p>如图，给图片RGB三通道上加减不同的失真值，进行颜色转换</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227181730903.png" alt="image-20201227181730903" /><figcaption>image-20201227181730903</figcaption>
</figure>
<h3 id="在训练期间实现变形implementing-distortions-during-training">在训练期间实现变形(Implementing distortions during training)</h3>
<p>通常将图片数据从硬盘上读取后，可以使用CPU多线性对图片进行变形处理如镜像、变色等，然后将构成的批数据或mini batch传输给其它线程(可以是CPU也可以是GPU)进行训练</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227182327667.png" alt="image-20201227182327667" /><figcaption>image-20201227182327667</figcaption>
</figure>
<p>将数据加载、增强和训练分开在不同的线程或进程，可以让两个部分并行进行，加快速度</p>
<h2 id="计算机视觉现状">计算机视觉现状</h2>
<h3 id="数据和手工工程data-vs.-hand-engineering">数据和手工工程(Data vs. hand-engineering)</h3>
<p>机器学习问题可以看成映射在在数据相对较少和大量数据之间的范围</p>
<figure>
<img src="https://gitee.com/Zephon-H/ImagesStore/raw/master/img/image-20201227215302872.png" alt="image-20201227215302872" /><figcaption>image-20201227215302872</figcaption>
</figure>
<p>通常认为学习算法有两种知识来源：</p>
<ol type="1">
<li>被标记的数据(x,y)</li>
<li>手工工程特征或网络体系结构或系统的其它组件</li>
</ol>
<p>因此，当没有太多的标签数据时，只需要更多地考虑手工工程，因此，计算机视觉在试图学习一个非常复杂的功能时，经常会感觉到没有足够的数据，这可能就是为什么计算机视觉从历史到现在都更多地依赖于手工工程，这也是计算机视觉邻域发展比较复杂网络架构的原因，正是由于缺乏较多的数据，因此，想要更好的表现就需要花更多的时间进行架构设计</p>
<h3 id="做好基准测试或赢得比赛的技巧tips-for-doing-well-on-benchmarkswinning-competitions">做好基准测试或赢得比赛的技巧(Tips for doing well on benchmarks/winning competitions)</h3>
<ol type="1">
<li>集成(Ensembling)
<ul>
<li>独立训练一些网络，然后将它们的结果平均后输出</li>
</ul></li>
<li>在测试时使用Multi-crop(Multi-crop at test time)
<ul>
<li>在多个版本测试图片和平均结果上运行分类器</li>
</ul></li>
</ol>
<h3 id="使用开源代码">使用开源代码</h3>
<ul>
<li>使用发布了文献的网络框架</li>
<li>如果可能的话使用已经开源的实现</li>
<li>使用预训练模型并在数据集上微调(fine tune)</li>
</ul>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Zephon
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://www.zephon.ml/2020/12/26/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/" title="卷积神经网络-实例探究">http://www.zephon.ml/2020/12/26/卷积神经网络-实例探究/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"><i class="fa fa-tag"></i> 计算机视觉</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/12/25/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%9F%BA%E7%A1%80/" rel="prev" title="卷积神经网络-基础">
      <i class="fa fa-chevron-left"></i> 卷积神经网络-基础
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/12/28/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="next" title="卷积神经网络-目标检测">
      卷积神经网络-目标检测 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC80MDY3OS8xNzIwNA=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6"><span class="nav-number">1.</span> <span class="nav-text">卷积神经网络-实例探究</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E5%AE%9E%E4%BE%8B%E5%88%86%E6%9E%90"><span class="nav-number">1.1.</span> <span class="nav-text">为什么要进行实例分析？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C"><span class="nav-number">1.2.</span> <span class="nav-text">经典网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#lenet-5"><span class="nav-number">1.2.1.</span> <span class="nav-text">LeNet-5</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#alexnet"><span class="nav-number">1.2.2.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vggnetvgg-16"><span class="nav-number">1.2.3.</span> <span class="nav-text">VGGNet(VGG-16)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9Cresidual-networksresnets"><span class="nav-number">1.3.</span> <span class="nav-text">残差网络(Residual Networks(ResNets))</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E5%9D%97residual-block"><span class="nav-number">1.3.1.</span> <span class="nav-text">残差块(Residual block)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9Cresidual-network"><span class="nav-number">1.3.2.</span> <span class="nav-text">残差网络(Residual Network)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C%E4%BC%9A%E4%BB%80%E4%B9%88%E6%9C%89%E7%94%A8"><span class="nav-number">1.4.</span> <span class="nav-text">残差网络会什么有用？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9Cnetwork-in-network%E5%92%8C11%E5%8D%B7%E7%A7%AF"><span class="nav-number">1.5.</span> <span class="nav-text">网络中的网络(Network in Network)和1×1卷积</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%8811%E5%8D%B7%E7%A7%AF"><span class="nav-number">1.5.1.</span> <span class="nav-text">为什么1×1卷积？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%80%E4%B8%AA%E5%BA%94%E7%94%A8"><span class="nav-number">1.5.2.</span> <span class="nav-text">1×1卷积的一个应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#inception-network"><span class="nav-number">1.6.</span> <span class="nav-text">Inception Network</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#motivation-for-inception-network"><span class="nav-number">1.6.1.</span> <span class="nav-text">Motivation for Inception Network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%88%90%E6%9C%AC%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">1.6.2.</span> <span class="nav-text">计算成本的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A811%E5%8D%B7%E7%A7%AF"><span class="nav-number">1.6.3.</span> <span class="nav-text">使用1×1卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#inception-%E6%A8%A1%E5%9D%97"><span class="nav-number">1.6.4.</span> <span class="nav-text">Inception 模块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#inception-network-1"><span class="nav-number">1.6.5.</span> <span class="nav-text">Inception Network</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.7.</span> <span class="nav-text">迁移学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BAdata-augmentation"><span class="nav-number">1.8.</span> <span class="nav-text">数据增强(Data Augmentation)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%99%AE%E9%80%9A%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95"><span class="nav-number">1.8.1.</span> <span class="nav-text">普通增强方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%9C%E8%89%B2%E8%BD%AC%E6%8D%A2"><span class="nav-number">1.8.2.</span> <span class="nav-text">颜色转换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8%E8%AE%AD%E7%BB%83%E6%9C%9F%E9%97%B4%E5%AE%9E%E7%8E%B0%E5%8F%98%E5%BD%A2implementing-distortions-during-training"><span class="nav-number">1.8.3.</span> <span class="nav-text">在训练期间实现变形(Implementing distortions during training)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B6"><span class="nav-number">1.9.</span> <span class="nav-text">计算机视觉现状</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%92%8C%E6%89%8B%E5%B7%A5%E5%B7%A5%E7%A8%8Bdata-vs.-hand-engineering"><span class="nav-number">1.9.1.</span> <span class="nav-text">数据和手工工程(Data vs. hand-engineering)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%81%9A%E5%A5%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E6%88%96%E8%B5%A2%E5%BE%97%E6%AF%94%E8%B5%9B%E7%9A%84%E6%8A%80%E5%B7%A7tips-for-doing-well-on-benchmarkswinning-competitions"><span class="nav-number">1.9.2.</span> <span class="nav-text">做好基准测试或赢得比赛的技巧(Tips for doing well on benchmarks&#x2F;winning competitions)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%BC%80%E6%BA%90%E4%BB%A3%E7%A0%81"><span class="nav-number">1.9.3.</span> <span class="nav-text">使用开源代码</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zephon"
      src="/images/avatar1.gif">
  <p class="site-author-name" itemprop="name">Zephon</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">167</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Zephon-H" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Zephon-H" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="/qq1528498238@gmail.com" title="E-Mail → qq1528498238@gmail.com"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zephon</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">805k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">12:12</span>
</div>

<br />
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("04/21/2019 15:54:40");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
